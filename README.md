# BSc Thesis research in Diagnostic Captioning

## Thesis paper
To be reviewed from my mentors and to be added..

## Abstract
Recent years have witnessed an increase in studies associated with image captioning, but little of that knowledge has been utilised in the biomedical field. This repo (as well as this thesis) addresses medical image captioning, referred as Diagnostic Captioning (DC), the task of assisting medical experts in diagnosis/report drafting. We present deep learning uni-modal, cross-modal and multi-modal methods that aim to generate a representative caption for a given medical image. The latter approaches, utilise the radiology concepts (tags) used by clinicians to describe a patient's image (e.g., X-Ray, CT scan, etc.) as an additional input data. These methods, have not been adequately applied to biomedical research. We also experimented with a novel technique that utilises the captions generated from all the systems implemented as part of this thesis. Lastly, this thesis concerns the participation of the AUEB NLP Group, with the author being the main driver, on the 2022 ImageCLEFmedical Caption Prediction task. Out of 10 teams, our team came in second on the primary evaluation metric, using an encoder-decoder approach, and first on the secondary metric, utilising an ensemble technique on our generated caption. More about our paper can be found [here](http://ceur-ws.org/Vol-3180/paper-101.pdf)

## Datasets
To be added..

## Enviroment setup
To be added..

## Instructions
To be added..

## License
[MIT License](https://github.com/zaaachos/bsc-thesis-in-diagnostic-captioning/blob/main/LICENSE)
